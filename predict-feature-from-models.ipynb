{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting features of images from features extracted from models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook predicts the size of an object, based on the features extracted from various vision models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import re\n",
    "import pingouin as pg\n",
    "from sklearn.random_projection import SparseRandomProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def predict_size_from_features(size=None, features=None, n_comp = 10, nrBS=20, k_parm=1000, nrFolds=10, regress_type='pls'):\n",
    "    \"\"\"\n",
    "    Predict affect based on features using specified regression model.\n",
    "    \n",
    "    Parameters:\n",
    "        size (np.array): Size variable, Mx1 array (size value for M images).\n",
    "        features (np.array): Neural/model responses, MxN array (M images units, N units).\n",
    "        nrBS (int): Number of bootstraps.\n",
    "        k_parm (int): Ridge regression parameter.\n",
    "        nrFolds (int): Number of cross-validation folds.\n",
    "        regress_type (str): Type of regression to use ('pls' or 'ridge').\n",
    "\n",
    "    Returns:\n",
    "        predictions (np.array): Predicted values, MxnrBS array.\n",
    "    \"\"\"\n",
    "    nrImages = depth.shape[0]\n",
    "    predictions = np.full((nrImages, nrBS), np.nan)\n",
    "    \n",
    "    for j in range(nrBS):\n",
    "        print(f' Bootstrap number: {j}')\n",
    "\n",
    "        # Initialize KFold cross-validation\n",
    "        kf = KFold(n_splits=nrFolds, shuffle=True, random_state=j)\n",
    "        \n",
    "        for train_index, test_index in kf.split(depth):\n",
    "            if regress_type == 'ridge':\n",
    "                # Ridge regression\n",
    "                ridge_model = Ridge(alpha=k_parm)\n",
    "                ridge_model.fit(features[:, train_index].T, depth[train_index])\n",
    "                predictions[test_index, j] = ridge_model.predict(features[:, test_index].T)\n",
    "                \n",
    "            elif regress_type == 'pls':\n",
    "                # PLS regression\n",
    "                pls_model = PLSRegression(n_components=n_comp)\n",
    "                pls_model.fit(features[train_index, :], depth[train_index])\n",
    "                predictions[test_index, j] = pls_model.predict(features[test_index, :]).flatten()\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(\"Invalid regression type. Use 'pls' or 'ridge'.\")\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load meta data\n",
    "\n",
    "meta_data_dict = pd.read_pickle('./meta_data/single_object_meta.pkl')\n",
    "meta_data = pd.read_csv(\"./meta_data/single_object_images.csv\")\n",
    "\n",
    "size_array = meta_data['size'].to_numpy().reshape((444, 1))\n",
    "\n",
    "# Sub-set the data \n",
    "# Here, I am subsetting it to single object images \n",
    "indices_to_keep =[]\n",
    "for key in meta_data_dict.keys():\n",
    "    match = re.search(r'im(\\d+)\\.png', key)\n",
    "    if match:\n",
    "        number = int(match.group(1))  # Extract the number\n",
    "        indices_to_keep.append(number)\n",
    "\n",
    "indices_to_keep = sorted(indices_to_keep) # These are the indices of the images we are running the analyses on\n",
    "\n",
    "# Choose the models you want to decode \n",
    "models = ['resnet-50',\n",
    "          'alexnet',\n",
    "          'vgg-16' \n",
    "          'resnet-50',\n",
    "          'resnet-101', \n",
    "          'resnet-152', \n",
    "          'densenet-121', \n",
    "          'densenet-201', \n",
    "          'densenet-169', \n",
    "          'squeezenet-1_0',\n",
    "          'squeezenet-1_1',\n",
    "          'inception-v3',\n",
    "          'resnext-wsl']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through the models \n",
    "for current_model in models:\n",
    "    \n",
    "    features = pd.read_pickle(f'./results/model_features/{current_model}_multiple_layers_features.pkl')\n",
    "    \n",
    "    # Create empty lists to store results for each layer\n",
    "    layer_results = []\n",
    "    \n",
    "    # Iterate through the layers\n",
    "    for key, value in features.items():\n",
    "        \n",
    "        # Get the layer name \n",
    "        layer = key\n",
    "        \n",
    "        print(f\"Processing layer {layer} of model {current_model}.\")\n",
    "        \n",
    "        # Preprocess the layer features\n",
    "        feature = np.array(value) \n",
    "        feature = feature.reshape(1600, -1)\n",
    "        feature = feature[indices_to_keep, :]\n",
    "        \n",
    "        # Dimentionality reduction\n",
    "        random_features =  np.full((444, 1000, 50), np.nan) \n",
    "\n",
    "        for i in range (50): \n",
    "            \n",
    "            reducer = SparseRandomProjection(n_components = 1000)\n",
    "            features_reduced = reducer.fit_transform(feature)\n",
    "            random_features[:, :, i] = features_reduced\n",
    "\n",
    "        reduced_dimensions_mean = np.mean(random_features, axis=2)\n",
    "\n",
    "        # Get the size predictions of this layer\n",
    "        \n",
    "        predictions = predict_size_from_features(size_array, reduced_dimensions_mean, n_comp= 20, regress_type='pls')\n",
    "        preds = np.mean(predictions, axis=1)\n",
    "    \n",
    "        results = pg.corr(preds, np.mean(size_array,axis=1), method='pearson')    \n",
    "        size_corr = results['r'].values[0]\n",
    "        size_conf_int = tuple(results['CI95%'].values[0])\n",
    "        \n",
    "        # Append results for this layer\n",
    "        layer_results.append({\n",
    "            'Layer': layer,\n",
    "            'Correlation_size': round(size_corr, 3),\n",
    "            'Size_Conf_Int_Lower': size_conf_int[0],\n",
    "            'Size_Conf_Int_Upper': size_conf_int[1],\n",
    "        })\n",
    "\n",
    "    # Convert layer results to a DataFrame after all layers have been processed\n",
    "    results_df = pd.DataFrame(layer_results)\n",
    "        \n",
    "    # Set Layer as the index\n",
    "    results_df = results_df.set_index('Layer')\n",
    "        \n",
    "    # Save to CSV for the current model\n",
    "    results_df.to_csv(f'./results/{current_model}_predictions_results.csv')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
