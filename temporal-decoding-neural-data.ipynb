{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding object category from the neural data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code decodes the object category from neural data, over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import zscore, norm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "print(\"Packages loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(features,labels,nrfolds=2,seed=0):\n",
    " \n",
    "    classes=np.unique(labels) # Gets the unique labels \n",
    "    \n",
    "    nrImages = features.shape[1] # Gets the number of images\n",
    "    \n",
    "    _,ind = np.unique(classes, return_inverse=True) # Assign index numbers to each label\n",
    "    \n",
    "    features = zscore(features,axis=0) # Scale data - convert them into z-score\n",
    "    \n",
    "    # features = preprocessing.scale(features) # Scale data another alternative - standardize it\n",
    "    \n",
    "    num_classes = len(classes) # Get how many unique labels (so classes) we have\n",
    "    # prob = np.zeros((nrImages,len(classes)))\n",
    "    # prob[:]=np.nan\n",
    "    prob = np.full((nrImages, len(classes)), np.nan)\n",
    "        \n",
    "    accuracies_test = []\n",
    "    accuracies_train = []\n",
    "    \n",
    "    # Using K-Fold Cross-Validation\n",
    "    skf = KFold(n_splits=nrfolds, shuffle=True, random_state = seed)\n",
    "    \n",
    "    for train_index, test_index in skf.split(features.T, labels):\n",
    "       \n",
    "        X_train_fold, X_test_fold = features[:,train_index], features[:,test_index]\n",
    "        y_train_fold, y_test_fold = labels[train_index], labels[test_index]\n",
    "\n",
    "        # Define & train the classifier\n",
    "        # clf = OneVsRestClassifier(SVC( C=5*10e4, kernel='linear', probability=True)).fit(XTrain.T, YTrain)\n",
    "        clf = OneVsRestClassifier(LogisticRegression(penalty='l2', C=5*10e4, max_iter=1000, class_weight='balanced')).fit(X_train_fold.T, y_train_fold)\n",
    "        \n",
    "        # Get class probabilities with & test the classifier\n",
    "        pred=clf.predict_proba(X_test_fold.T)\n",
    "        \n",
    "        # Save the probabilities predicted by the classifier, of this fold\n",
    "        prob[test_index,0:num_classes]=pred\n",
    "        \n",
    "        accuracies_test.append(clf.score(X_test_fold.T, y_test_fold))\n",
    "        \n",
    "        accuracies_train.append(clf.score(X_train_fold.T, y_train_fold))\n",
    "\n",
    "    return prob, accuracies_test, accuracies_train\n",
    "\n",
    "def get_probability_correct(prob, labels, class_order):\n",
    "    \n",
    "    # This function calculates the ratio of the correctly predicted labels \n",
    "    \n",
    "    nrImages = prob.shape[0]\n",
    "    \n",
    "    class_order=np.unique(labels) \n",
    "    \n",
    "    pc = np.full((nrImages, len(class_order)), np.nan)\n",
    "    \n",
    "    _,ind = np.unique(labels, return_inverse=True)\n",
    "    \n",
    "    for i in range(nrImages):\n",
    "        \n",
    "        # Create a Boolean array, setting the label of the current image as True and the rest False\n",
    "        loc_target = labels[i]==class_order \n",
    "        \n",
    "        # Probability of predicting the correct label / probabilities for all classes + Probability of predicting the correct label\n",
    "        # Ratio of how much the model favoured the true label, compared to others\n",
    "        # So the cell of each label in a given image's row, shows how much the correct label is favoured over that label. \n",
    "        pc[i,:] = np.divide(\n",
    "                            prob[i,loc_target], \n",
    "                            prob[i,:] + prob[i,loc_target]\n",
    "                            )\n",
    "        \n",
    "        # Sets the correct label's cell to NaN, to mark the correct response\n",
    "        pc[i,loc_target] = np.nan \n",
    "        \n",
    "    return pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the meta data\n",
    "meta= pd.read_csv('./data/meta_data.csv')\n",
    "\n",
    "# Load the cleaned neural data\n",
    "all_rates_avg = np.load('./data/neural_data/all_rates.npy')\n",
    "all_rates = np.load('./data/neural_data/all_rates_repetitions.npy')\n",
    "\n",
    "# Get the total number of images\n",
    "nrImages = all_rates_avg.shape[1] \n",
    " \n",
    "# Create time bins\n",
    "bin_size = 4 # bins of 40ms \n",
    "bins = [all_rates_avg[i:i + bin_size] for i in range(0, all_rates_avg.shape[0] - bin_size + 1, 1)]\n",
    "bins_with_reps = [all_rates[i:i + bin_size] for i in range(0, all_rates.shape[0] - bin_size + 1, 1)]\n",
    "\n",
    "# Initialize data frames\n",
    "i_1_df = pd.DataFrame()\n",
    "bin_performance_summary_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the time bins, get the object decoding accuracy for each time bin\n",
    "for idx, current_bin in enumerate(bins):\n",
    "    \n",
    "    start_time = idx * 10\n",
    "    end_time = (idx + 3) * 10\n",
    "    print(f\"Processing bin {idx}: Time frame from {start_time} to {end_time}\")\n",
    "            \n",
    "    # Pre-process the bin's neural data\n",
    "    current_bin = np.mean(current_bin, axis = 0)  # [images, channels]\n",
    "    neural_rates = current_bin.T # we should use [channels, images]\n",
    "    \n",
    "    print(f\"Getting the labels ...\")\n",
    "    labels = meta['obj'].to_numpy().astype(str)  # Get the labels from metadata\n",
    "    unique_labels = np.array(list(dict.fromkeys(labels)))\n",
    "    \n",
    "    i_1 = np.zeros((nrImages,20), dtype=float)\n",
    "    i_1[:]=np.nan\n",
    "            \n",
    "    accuracies_test_list = []\n",
    "    accuracies_train_list = []\n",
    "    \n",
    "    for j in range(20):\n",
    "        \n",
    "        print('Decoding nrBS: '+str(j))\n",
    "        \n",
    "        # Train and test the decoder for this bootstrap, get the probabilities predicted\n",
    "        p, accuracies_test, accuracies_train = decode(neural_rates, labels, nrfolds=10,  seed=j) # [n_image, n_labels] For each image, a probability value assigned for each label.\n",
    "        \n",
    "        accuracies_test_list.append(accuracies_test)\n",
    "        accuracies_train_list.append(accuracies_train)\n",
    "        \n",
    "        # Get the accuracy from the probabilities (predictions)\n",
    "        pc = get_probability_correct(p, labels, np.array(unique_labels)) # [n_image, n_labels] For each image, a probability value assigned for each label.\n",
    "        \n",
    "        # Probability of the correct label being chosen, over the other labels\n",
    "        i_1[:,j] = np.nanmean(pc, axis=1) \n",
    "    \n",
    "    plt.hist(np.mean(i_1,axis=1))\n",
    "    plt.title(f'{start_time} - {end_time} ms')\n",
    "    plt.savefig(f'./results/neural_decoding_performance_{start_time}.png')\n",
    "    plt.show()\n",
    "    print(\"Saved the figure ...\")\n",
    "    plt.clf() \n",
    "\n",
    "    bin_df = pd.DataFrame(i_1, columns=[f'{start_time}_{i}' for i in range(20)]) \n",
    "    i_1_df = pd.concat([i_1_df, bin_df], axis=1)\n",
    "    print(\"Updated results dataframe ...\")\n",
    "\n",
    "    bin_performance_summary = pd.DataFrame(np.mean(i_1,axis=1), columns=[f'{start_time}']) \n",
    "    bin_performance_summary_df = pd.concat([bin_performance_summary_df, bin_performance_summary], axis=1)\n",
    "    print(\"Updated summary dataframe ...\")\n",
    "\n",
    "i_1_df.to_csv('./results/neural_decoding_results.csv', index = False)\n",
    "bin_performance_summary_df.to_csv('./results/neural_decoding_results_summary.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
